{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "PySpark.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hqIj-w-iiD"
      },
      "source": [
        "## Tazeem Khan\n",
        "## Kritik Seth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYc5Ale8uthc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459b28f2-8910-4fb4-b326-02ba6b081142"
      },
      "source": [
        " !pip install pyspark \n",
        " !pip install findspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 70kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 37.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=dd32506107df28cfa580c25cb4b4addf6edb09ab21d4ae168caf0bdb100c7ac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n",
            "Collecting findspark\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QdAx3F_muIG"
      },
      "source": [
        "import findspark\n",
        "# findspark.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo1YJZGAmuIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6777b354-43f7-49f1-9c06-8bbbc68dba2b"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.sql(\"select 'spark' as hello\")\n",
        "df.show()\n",
        "spark.stop()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|spark|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjpROz-SmuIN"
      },
      "source": [
        "# pyspark.SparkContext (\n",
        "#    master = None,\n",
        "#    appName = None, \n",
        "#    sparkHome = None, \n",
        "#    pyFiles = None, \n",
        "#    environment = None, \n",
        "#    batchSize = 0, \n",
        "#    serializer = PickleSerializer(), \n",
        "#    conf = None, \n",
        "#    gateway = None, \n",
        "#    jsc = None, \n",
        "#   #  profiler_cls = <class 'pyspark.profiler.BasicProfiler'>\n",
        "#   profiler_cls = 'pyspark.profiler.BasicProfiler'\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3HjUXoPmuIO"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext('local', 'test_1')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCV4qmVjmuIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "ad0c36ce-c04e-4293-9b21-2a1b54ede506"
      },
      "source": [
        "sc"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://9c33bb5ba5d5:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>test_1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=test_1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiX79dermuIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab845473-541e-4aaa-da8c-11bfccc2f421"
      },
      "source": [
        "x= ['Python', 'is', 'really', 'conveniant','Colab','is','very','fast']\n",
        "print(sorted(x))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Colab', 'Python', 'conveniant', 'fast', 'is', 'is', 'really', 'very']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6puoXq1muIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f905f65-5674-4ef4-81fa-974ac558588f"
      },
      "source": [
        "sorted(x, key = lambda arg : arg.lower())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab', 'conveniant', 'fast', 'is', 'is', 'Python', 'really', 'very']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gozUaqe9muIP"
      },
      "source": [
        "## filter()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3pP7GdUmuIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3e0a3fe-296a-42bb-ec2c-a82667251d3b"
      },
      "source": [
        "list(filter(lambda arg: len(arg) < 5, x))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is', 'is', 'very', 'fast']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jgk8UW-muIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca19fae-72d5-4620-8ef9-b2851175a5a1"
      },
      "source": [
        "def check_length(x):\n",
        "    return len(x)<5\n",
        "\n",
        "l1=[]\n",
        "\n",
        "for i in x:\n",
        "    if check_length(i):\n",
        "        l1.append(i)\n",
        "        \n",
        "print(l1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['is', 'is', 'very', 'fast']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67sIq02pmuIQ"
      },
      "source": [
        "## map()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbKoYUcfmuIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6f21a0f-2a20-43e0-83ba-b71fd0ee2b39"
      },
      "source": [
        "print(list(map(lambda arg : check_length(arg), x)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False, False, True, True, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3zcAO9HmuIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c23602a-de58-413f-a848-069257015f5b"
      },
      "source": [
        "def check_length(x):\n",
        "    return len(x)<5\n",
        "\n",
        "l1=[]\n",
        "\n",
        "for i in x:\n",
        "    l1.append(check_length(i))\n",
        "        \n",
        "print(l1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False, False, True, True, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7F2PukzmuIR"
      },
      "source": [
        "## reduce()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHWzhwiimuIR"
      },
      "source": [
        "def concat(x,y):\n",
        "    print( f'{x} + {y} = {x+y}')\n",
        "    return x + y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZcWaajamuIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b49191-4e17-40ef-ae99-9c9f5c57bc14"
      },
      "source": [
        "from functools import reduce\n",
        "print(reduce(lambda i,j: concat(i,j), x))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python + is = Pythonis\n",
            "Pythonis + really = Pythonisreally\n",
            "Pythonisreally + conveniant = Pythonisreallyconveniant\n",
            "Pythonisreallyconveniant + Colab = PythonisreallyconveniantColab\n",
            "PythonisreallyconveniantColab + is = PythonisreallyconveniantColabis\n",
            "PythonisreallyconveniantColabis + very = PythonisreallyconveniantColabisvery\n",
            "PythonisreallyconveniantColabisvery + fast = PythonisreallyconveniantColabisveryfast\n",
            "PythonisreallyconveniantColabisveryfast\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARo_EVKPmuIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ca60bd-b470-461d-a145-387ba380f5c5"
      },
      "source": [
        "print(reduce(lambda i,j: concat(i,j), range(10)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 + 1 = 1\n",
            "1 + 2 = 3\n",
            "3 + 3 = 6\n",
            "6 + 4 = 10\n",
            "10 + 5 = 15\n",
            "15 + 6 = 21\n",
            "21 + 7 = 28\n",
            "28 + 8 = 36\n",
            "36 + 9 = 45\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl0xeq7smuIS"
      },
      "source": [
        "## PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGMo4gs2yfor"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7wBSYSKmuIS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cd0306db-ddeb-4ac4-db26-47b9b29451a2"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pyspark\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "os.getcwd()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ciCnK0muIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35151ef-cb37-4ec2-ec83-b9d856deb0c9"
      },
      "source": [
        "txt = sc.textFile('/content/Pyspark.txt')\n",
        "print(txt.count())\n",
        "\n",
        "python_lines = txt.filter(lambda line: 'spark' in line.lower())\n",
        "print(python_lines.count())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_2yrDfsmuIS"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we_HxLjsmuIT"
      },
      "source": [
        "## RDD Resilient Distributed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNWzUX75muIT"
      },
      "source": [
        "sc = pyspark.SparkContext('local[*]')\n",
        "\n",
        "words = sc.parallelize(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])\n",
        "\n",
        "words.count()\n",
        "\n",
        "words.collect()\n",
        "\n",
        "def test(x):\n",
        "    print(x)\n",
        "\n",
        "test_result = words.foreach(test)\n",
        "sc.stop()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-TfdxUsmuIT"
      },
      "source": [
        "sc = pyspark.SparkContext('local[*]', 'cache check')\n",
        "\n",
        "words = sc.parallelize(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQP5PWk5muIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec9ab99-9e54-4269-ebfe-9b560f77960b"
      },
      "source": [
        "words.persist().is_cached"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_ybt5SmuIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba929f29-bb1f-4334-c5d4-84c298ed76b2"
      },
      "source": [
        "words.cache()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ev6G1C0muIU"
      },
      "source": [
        "## Shared Variables\n",
        "\n",
        "* Broadcast\n",
        "* Accumulator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCpFCJRImuIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a69cbe7-876b-4ee2-e230-6aa5413781eb"
      },
      "source": [
        "words_2 = sc.broadcast(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])\n",
        "data = words_2.value\n",
        "print(f'Stored data is {data}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stored data is ['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9i-nft3muIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1d0b9b8d-8276-4ff7-99a7-2785accc9878"
      },
      "source": [
        "words_2.value[2]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'solaris'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLgQejwKmuIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f005f6b-b708-48e6-90ae-2a3d113825eb"
      },
      "source": [
        "y = sc.accumulator(100)\n",
        "def f(x):\n",
        "    global y\n",
        "    y+=x\n",
        "    \n",
        "rdd = sc.parallelize([10,20,30,40,50])\n",
        "rdd.foreach(f)\n",
        "\n",
        "final = y.value\n",
        "print(final)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWx22ZUzmuIU"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX10mLeKmuIV"
      },
      "source": [
        "## Spark mllib\n",
        "\n",
        "* classification\n",
        "* regression\n",
        "* clustering\n",
        "* linalg\n",
        "* recommendation\n",
        "* fpm"
      ]
    }
  ]
}